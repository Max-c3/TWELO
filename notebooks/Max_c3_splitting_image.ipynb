{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MUlsJO7-zYqv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QXgwNl2c-BO"
      },
      "source": [
        "# Function: **luc_coordinates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wVVGT1tdXaeO"
      },
      "outputs": [],
      "source": [
        "def luc_coordinates(width, height, num_width_comp, num_height_comp, comp_size):\n",
        "  ''' A function that takes as an input:\n",
        "  width_comp = number of compartments for the width (e.g. 8)\n",
        "  height_comp = number of compartments for the height (e.g. 6)\n",
        "  comp_size = size of each compartment (e.g. 640)\n",
        "  and returns the coordinates of the left-upper-corner (luc) of\n",
        "  each compartment\n",
        "  '''\n",
        "\n",
        "  # Step size is the size of the compartments unique pixels horizontally and vertically\n",
        "  step_size_horiz = width / num_width_comp\n",
        "  step_size_vert = height / num_height_comp\n",
        "\n",
        "  # Defining how much overlap there will be between each compartment vertically and horizontally\n",
        "  overlap_horiz = int(((comp_size * num_width_comp) - width)/num_width_comp)\n",
        "  overlap_vert = int(((comp_size * num_height_comp) - height)/num_height_comp)\n",
        "\n",
        "  #creating a list with all the x_coordinates for the compartments (8)\n",
        "  x_coordinates = [0]\n",
        "  [x_coordinates.append(int(ele * step_size_horiz)) for ele in range(1, num_width_comp)]\n",
        "\n",
        "  # creating a list with all the y_coordinates for the compartments (6)\n",
        "  y_coordinates = [0]\n",
        "  [y_coordinates.append(int(ele * step_size_vert)) for ele in range(1, num_height_comp)]\n",
        "\n",
        "\n",
        "  # Creating a dictionary with the coordinates\n",
        "  coordinates_dict = {}\n",
        "  b = 0 # no inherent important meaning\n",
        "\n",
        "  for ele in range (0, num_height_comp):\n",
        "    for i in range (0, num_width_comp):\n",
        "      a = [x_coordinates[i], y_coordinates[ele]]\n",
        "      b += 1\n",
        "      coordinates_dict[f'cor_{b}'] = a\n",
        "\n",
        "  return coordinates_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cor_1': [0, 0],\n",
              " 'cor_2': [500, 0],\n",
              " 'cor_3': [1000, 0],\n",
              " 'cor_4': [1500, 0],\n",
              " 'cor_5': [2000, 0],\n",
              " 'cor_6': [2500, 0],\n",
              " 'cor_7': [3000, 0],\n",
              " 'cor_8': [3500, 0],\n",
              " 'cor_9': [0, 500],\n",
              " 'cor_10': [500, 500],\n",
              " 'cor_11': [1000, 500],\n",
              " 'cor_12': [1500, 500],\n",
              " 'cor_13': [2000, 500],\n",
              " 'cor_14': [2500, 500],\n",
              " 'cor_15': [3000, 500],\n",
              " 'cor_16': [3500, 500],\n",
              " 'cor_17': [0, 1000],\n",
              " 'cor_18': [500, 1000],\n",
              " 'cor_19': [1000, 1000],\n",
              " 'cor_20': [1500, 1000],\n",
              " 'cor_21': [2000, 1000],\n",
              " 'cor_22': [2500, 1000],\n",
              " 'cor_23': [3000, 1000],\n",
              " 'cor_24': [3500, 1000],\n",
              " 'cor_25': [0, 1500],\n",
              " 'cor_26': [500, 1500],\n",
              " 'cor_27': [1000, 1500],\n",
              " 'cor_28': [1500, 1500],\n",
              " 'cor_29': [2000, 1500],\n",
              " 'cor_30': [2500, 1500],\n",
              " 'cor_31': [3000, 1500],\n",
              " 'cor_32': [3500, 1500],\n",
              " 'cor_33': [0, 2000],\n",
              " 'cor_34': [500, 2000],\n",
              " 'cor_35': [1000, 2000],\n",
              " 'cor_36': [1500, 2000],\n",
              " 'cor_37': [2000, 2000],\n",
              " 'cor_38': [2500, 2000],\n",
              " 'cor_39': [3000, 2000],\n",
              " 'cor_40': [3500, 2000],\n",
              " 'cor_41': [0, 2500],\n",
              " 'cor_42': [500, 2500],\n",
              " 'cor_43': [1000, 2500],\n",
              " 'cor_44': [1500, 2500],\n",
              " 'cor_45': [2000, 2500],\n",
              " 'cor_46': [2500, 2500],\n",
              " 'cor_47': [3000, 2500],\n",
              " 'cor_48': [3500, 2500]}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Defining the inputs of the function\n",
        "\n",
        "width = 4000\n",
        "height = 3000\n",
        "\n",
        "num_width_comp = 8\n",
        "num_height_comp = 6\n",
        "comp_size = 640\n",
        "\n",
        "coordinates_dict = luc_coordinates(width, height, num_width_comp, num_height_comp, comp_size)\n",
        "coordinates_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwKh9pskc1E7"
      },
      "source": [
        "# Function: **splitting_into_compartments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RrcFVt4KX3xo"
      },
      "outputs": [],
      "source": [
        "def splitting_into_compartments(tensor):\n",
        "  '''\n",
        "  Takes as an input the Tensor that represents the\n",
        "  whole image that is supposed to be split into compartments.\n",
        "  The tensor should have the shape (4140, 3140, 3)\n",
        "  '''\n",
        "\n",
        "  # Calling the function 'luc_coordinates' and saving the resulting dictionary of coordinates in a variable\n",
        "  coordinates_dict = luc_coordinates(width, height, num_width_comp, num_height_comp, comp_size)\n",
        "\n",
        "  slize_size = 640\n",
        "\n",
        "  # Turning the coordinates into a list\n",
        "  coordinates_list = [value for key, value in coordinates_dict.items()]\n",
        "\n",
        "  # creating a for loop for getting the correct slizing integers and putting them into a dictionary\n",
        "  slicing_dict = {}\n",
        "\n",
        "  for i in range (0, 48):\n",
        "    slice_1, slice_2 = coordinates_list[i][0], coordinates_list[i][1]\n",
        "    slice_1_a = slice_1\n",
        "    slice_1_b = slice_1_a + slize_size\n",
        "    slice_2_a = slice_2\n",
        "    slice_2_b = slice_2_a + slize_size\n",
        "    slicing_dict[i] = [slice_1_a, slice_1_b, slice_2_a, slice_2_b]\n",
        "\n",
        "  # slicing the input-tensor to get (48) of shape (640, 640, 3)\n",
        "\n",
        "  # version tensor.shape = (4140, 3140, 3)\n",
        "#   list_of_tensors = [tensor[slicing_dict[ele][0]:slicing_dict[ele][1],\n",
        "#                                  slicing_dict[ele][2]:slicing_dict[ele][3],\n",
        "\n",
        "#                                  ] for ele in range (0, 48)]\n",
        "\n",
        "  #version tensor.shape = (3140, 4140, 3)\n",
        "  list_of_tensors = [tensor[slicing_dict[ele][2]:slicing_dict[ele][3],\n",
        "                            slicing_dict[ele][0]:slicing_dict[ele][1],\n",
        "\n",
        "                                 ] for ele in range (0, 48)]\n",
        "\n",
        "  #optional, if needed:\n",
        "  compartment_tensors = np.array(list_of_tensors)\n",
        "\n",
        "  return compartment_tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48, 640, 640, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = np.random.randint(0, 256, (3140, 4140, 3), dtype=np.uint8)\n",
        "tensor.shape\n",
        "compartment_tensors = splitting_into_compartments(tensor)\n",
        "compartment_tensors.shape\n",
        "\n",
        "# a = compartment_tensors[0,:,:,:]\n",
        "# b = compartment_tensors[1,:,:,:]\n",
        "# c = compartment_tensors[2,:,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Assuming your tensor is a NumPy array\n",
        "tensor = np.random.randint(0, 256, (640, 640, 3), dtype=np.uint8)\n",
        "tensor.shape\n",
        "\n",
        "# Convert the NumPy array to an Image object\n",
        "image = Image.fromarray(a)\n",
        "\n",
        "# Save the image as a PNG file\n",
        "image.save('output_image.png')\n",
        "\n",
        "# Or save as a JPEG file\n",
        "image.save('output_image.jpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Can be put into a function as well\n",
        "\n",
        "for i in range(0, 48):\n",
        "    compartment = compartment_tensors[i,:,:,:]  # object shape (640, 640, 3)\n",
        "    image = Image.fromarray(compartment)\n",
        "    image.save(f'comp_{i}.png')\n",
        "\n",
        "# Should do the trick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZSC6zRqDZWu8",
        "outputId": "9d93c88d-f4de-4da3-c87f-b7ed0eaaa3c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 91.8 ms, sys: 220 ms, total: 311 ms\n",
            "Wall time: 313 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(48, 640, 640, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "tensor_ones = np.ones((4140, 3140, 3))\n",
        "splitting_into_compartments(tensor_ones).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtY97t5sdF2-"
      },
      "source": [
        "# Function: **slicing_dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qyL8Fw-adN0A"
      },
      "outputs": [],
      "source": [
        "def slicing_dictionary(tensor):\n",
        "\n",
        "  # Calling the function 'luc_coordinates' and saving the resulting dictionary of coordinates in a variable\n",
        "  coordinates_dict = luc_coordinates(num_width_comp, num_height_comp, comp_size)\n",
        "\n",
        "  slize_size = 640\n",
        "\n",
        "  # Turning the coordinates into a list\n",
        "  coordinates_list = [value for key, value in coordinates_dict.items()]\n",
        "\n",
        "  # creating a for loop for getting the correct slizing integers and putting them into a dictionary\n",
        "  slicing_dict = {}\n",
        "\n",
        "  for i in range (0, 48):\n",
        "    slice_1, slice_2 = coordinates_list[i][0], coordinates_list[i][1]\n",
        "    slice_1_a = slice_1\n",
        "    slice_1_b = slice_1_a + slize_size\n",
        "    slice_2_a = slice_2\n",
        "    slice_2_b = slice_2_a + slize_size\n",
        "    slicing_dict[i] = [slice_1_a, slice_1_b, slice_2_a, slice_2_b]\n",
        "\n",
        "  return slicing_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwhMoxMtdiwr",
        "outputId": "6fee1d6d-290f-4335-bd6c-d43e92436f03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [0, 640, 0, 640],\n",
              " 1: [500, 1140, 0, 640],\n",
              " 2: [1000, 1640, 0, 640],\n",
              " 3: [1500, 2140, 0, 640],\n",
              " 4: [2000, 2640, 0, 640],\n",
              " 5: [2500, 3140, 0, 640],\n",
              " 6: [3000, 3640, 0, 640],\n",
              " 7: [3500, 4140, 0, 640],\n",
              " 8: [0, 640, 500, 1140],\n",
              " 9: [500, 1140, 500, 1140],\n",
              " 10: [1000, 1640, 500, 1140],\n",
              " 11: [1500, 2140, 500, 1140],\n",
              " 12: [2000, 2640, 500, 1140],\n",
              " 13: [2500, 3140, 500, 1140],\n",
              " 14: [3000, 3640, 500, 1140],\n",
              " 15: [3500, 4140, 500, 1140],\n",
              " 16: [0, 640, 1000, 1640],\n",
              " 17: [500, 1140, 1000, 1640],\n",
              " 18: [1000, 1640, 1000, 1640],\n",
              " 19: [1500, 2140, 1000, 1640],\n",
              " 20: [2000, 2640, 1000, 1640],\n",
              " 21: [2500, 3140, 1000, 1640],\n",
              " 22: [3000, 3640, 1000, 1640],\n",
              " 23: [3500, 4140, 1000, 1640],\n",
              " 24: [0, 640, 1500, 2140],\n",
              " 25: [500, 1140, 1500, 2140],\n",
              " 26: [1000, 1640, 1500, 2140],\n",
              " 27: [1500, 2140, 1500, 2140],\n",
              " 28: [2000, 2640, 1500, 2140],\n",
              " 29: [2500, 3140, 1500, 2140],\n",
              " 30: [3000, 3640, 1500, 2140],\n",
              " 31: [3500, 4140, 1500, 2140],\n",
              " 32: [0, 640, 2000, 2640],\n",
              " 33: [500, 1140, 2000, 2640],\n",
              " 34: [1000, 1640, 2000, 2640],\n",
              " 35: [1500, 2140, 2000, 2640],\n",
              " 36: [2000, 2640, 2000, 2640],\n",
              " 37: [2500, 3140, 2000, 2640],\n",
              " 38: [3000, 3640, 2000, 2640],\n",
              " 39: [3500, 4140, 2000, 2640],\n",
              " 40: [0, 640, 2500, 3140],\n",
              " 41: [500, 1140, 2500, 3140],\n",
              " 42: [1000, 1640, 2500, 3140],\n",
              " 43: [1500, 2140, 2500, 3140],\n",
              " 44: [2000, 2640, 2500, 3140],\n",
              " 45: [2500, 3140, 2500, 3140],\n",
              " 46: [3000, 3640, 2500, 3140],\n",
              " 47: [3500, 4140, 2500, 3140]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_ones = np.ones((4140, 3140, 3))\n",
        "slicing_dictionary(tensor_ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBIRVA98xkF8"
      },
      "source": [
        "# Step after Step for the 'luc_coordinates'-function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6SmXaT7kxTEP"
      },
      "outputs": [],
      "source": [
        "# 1. compartment\n",
        "width = 4000\n",
        "height = 3000\n",
        "\n",
        "#Defining the inputs of the function\n",
        "num_width_comp = 8\n",
        "num_height_comp = 6\n",
        "comp_size = 640\n",
        "\n",
        " # Step size is the size of the compartments unique pixels horizontally and vertically\n",
        "step_size_horiz = width / num_width_comp # = 500\n",
        "step_size_vert = height / num_height_comp # = 500\n",
        "\n",
        "# Defining how much overlap there will be between each compartment vertically and horizontally\n",
        "overlap_horiz = int(((comp_size * num_width_comp) - width)/num_width_comp) # = 140\n",
        "overlap_vert = int(((comp_size * num_height_comp) - height)/num_height_comp) # = 140"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACeSSxbtdfPx",
        "outputId": "030f6388-f8e6-4085-f5ca-2c0518547687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
            "[0, 500, 1000, 1500, 2000, 2500]\n"
          ]
        }
      ],
      "source": [
        "#creating a list with all the x_coordinates for the first row of compartments (8)\n",
        "x_coordinates = [0]\n",
        "[x_coordinates.append(int(ele * step_size_horiz)) for ele in range(1, num_width_comp)]\n",
        "\n",
        "# Coordinates we want for a shape of (4140, 3140): [0, 500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
        "\n",
        "# creating a list with all the y_coordinates for the first row of compartments (8)\n",
        "# Is always the same coordinate -> 0 (or 1)\n",
        "y_coordinates = [0]\n",
        "[y_coordinates.append(int(ele * step_size_vert)) for ele in range(1, num_height_comp)]\n",
        "\n",
        "print(x_coordinates)\n",
        "print(y_coordinates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VvdKDd_cVCS"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: For achieving the same overlap for each compartment, we need to add padding of 70 pixels at each side of the total image (4000 x 3000)\n",
        "# -> The tensor has to be increased at the right positions by that\n",
        "# IMPORTANT: The coordinates have to altered when adding the padding (+ 70 each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxQPfJkrZaSo",
        "outputId": "7518576b-618a-457f-9a89-4f19cb891bb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cor_1': [0, 0],\n",
              " 'cor_2': [500, 0],\n",
              " 'cor_3': [1000, 0],\n",
              " 'cor_4': [1500, 0],\n",
              " 'cor_5': [2000, 0],\n",
              " 'cor_6': [2500, 0],\n",
              " 'cor_7': [3000, 0],\n",
              " 'cor_8': [3500, 0],\n",
              " 'cor_9': [0, 500],\n",
              " 'cor_10': [500, 500],\n",
              " 'cor_11': [1000, 500],\n",
              " 'cor_12': [1500, 500],\n",
              " 'cor_13': [2000, 500],\n",
              " 'cor_14': [2500, 500],\n",
              " 'cor_15': [3000, 500],\n",
              " 'cor_16': [3500, 500],\n",
              " 'cor_17': [0, 1000],\n",
              " 'cor_18': [500, 1000],\n",
              " 'cor_19': [1000, 1000],\n",
              " 'cor_20': [1500, 1000],\n",
              " 'cor_21': [2000, 1000],\n",
              " 'cor_22': [2500, 1000],\n",
              " 'cor_23': [3000, 1000],\n",
              " 'cor_24': [3500, 1000],\n",
              " 'cor_25': [0, 1500],\n",
              " 'cor_26': [500, 1500],\n",
              " 'cor_27': [1000, 1500],\n",
              " 'cor_28': [1500, 1500],\n",
              " 'cor_29': [2000, 1500],\n",
              " 'cor_30': [2500, 1500],\n",
              " 'cor_31': [3000, 1500],\n",
              " 'cor_32': [3500, 1500],\n",
              " 'cor_33': [0, 2000],\n",
              " 'cor_34': [500, 2000],\n",
              " 'cor_35': [1000, 2000],\n",
              " 'cor_36': [1500, 2000],\n",
              " 'cor_37': [2000, 2000],\n",
              " 'cor_38': [2500, 2000],\n",
              " 'cor_39': [3000, 2000],\n",
              " 'cor_40': [3500, 2000],\n",
              " 'cor_41': [0, 2500],\n",
              " 'cor_42': [500, 2500],\n",
              " 'cor_43': [1000, 2500],\n",
              " 'cor_44': [1500, 2500],\n",
              " 'cor_45': [2000, 2500],\n",
              " 'cor_46': [2500, 2500],\n",
              " 'cor_47': [3000, 2500],\n",
              " 'cor_48': [3500, 2500]}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating each coordinate for the 48 compartments\n",
        "\n",
        "coordinates_dict = {}\n",
        "b = 0 # no inherent important meaning\n",
        "\n",
        "for ele in range (0, num_height_comp):\n",
        "  for i in range (0, num_width_comp):\n",
        "    a = [x_coordinates[i], y_coordinates[ele]]\n",
        "    b += 1\n",
        "    coordinates_dict[f'cor_{b}'] = a\n",
        "\n",
        "coordinates_dict\n",
        "\n",
        "# coordinates_dict -> contains values that represent x-coordinates and y_coordinates for the upper left corner of a compartment of the input size (e.g. 640 x 640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGGFbl9RcvMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izj5PApucFj8"
      },
      "source": [
        "# Step after Step for the 'splitting_into_compartments'-function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AL_3aszyZbI"
      },
      "outputs": [],
      "source": [
        "# Calling the function and saving the resulting dictionary of coordinates in a variable\n",
        "coordinates_dict = luc_coordinates(num_width_comp, num_height_comp, comp_size)\n",
        "\n",
        "# I want to have an output that slices the tensor nicely and comparts it into 48 tensors\n",
        "# Create a tensor filled with ones\n",
        "tensor_ones = np.ones((4140, 3140, 3))\n",
        "tensor_ones.shape\n",
        "\n",
        "tensor_ones[1:641, 1:641,].shape\n",
        "slize_size = 640\n",
        "\n",
        "coordinates_list = []\n",
        "\n",
        "\n",
        "for keys, value in coordinates_dict.items():\n",
        "  coordinates_list.append(value)\n",
        "\n",
        "coordinates_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSgVtHxbTmw4",
        "outputId": "b2c8bd8d-07b1-4697-99ff-a8b0f5e8d74b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [0, 640, 0, 640],\n",
              " 1: [500, 1140, 0, 640],\n",
              " 2: [1000, 1640, 0, 640],\n",
              " 3: [1500, 2140, 0, 640],\n",
              " 4: [2000, 2640, 0, 640],\n",
              " 5: [2500, 3140, 0, 640],\n",
              " 6: [3000, 3640, 0, 640],\n",
              " 7: [3500, 4140, 0, 640],\n",
              " 8: [0, 640, 500, 1140],\n",
              " 9: [500, 1140, 500, 1140],\n",
              " 10: [1000, 1640, 500, 1140],\n",
              " 11: [1500, 2140, 500, 1140],\n",
              " 12: [2000, 2640, 500, 1140],\n",
              " 13: [2500, 3140, 500, 1140],\n",
              " 14: [3000, 3640, 500, 1140],\n",
              " 15: [3500, 4140, 500, 1140],\n",
              " 16: [0, 640, 1000, 1640],\n",
              " 17: [500, 1140, 1000, 1640],\n",
              " 18: [1000, 1640, 1000, 1640],\n",
              " 19: [1500, 2140, 1000, 1640],\n",
              " 20: [2000, 2640, 1000, 1640],\n",
              " 21: [2500, 3140, 1000, 1640],\n",
              " 22: [3000, 3640, 1000, 1640],\n",
              " 23: [3500, 4140, 1000, 1640],\n",
              " 24: [0, 640, 1500, 2140],\n",
              " 25: [500, 1140, 1500, 2140],\n",
              " 26: [1000, 1640, 1500, 2140],\n",
              " 27: [1500, 2140, 1500, 2140],\n",
              " 28: [2000, 2640, 1500, 2140],\n",
              " 29: [2500, 3140, 1500, 2140],\n",
              " 30: [3000, 3640, 1500, 2140],\n",
              " 31: [3500, 4140, 1500, 2140],\n",
              " 32: [0, 640, 2000, 2640],\n",
              " 33: [500, 1140, 2000, 2640],\n",
              " 34: [1000, 1640, 2000, 2640],\n",
              " 35: [1500, 2140, 2000, 2640],\n",
              " 36: [2000, 2640, 2000, 2640],\n",
              " 37: [2500, 3140, 2000, 2640],\n",
              " 38: [3000, 3640, 2000, 2640],\n",
              " 39: [3500, 4140, 2000, 2640],\n",
              " 40: [0, 640, 2500, 3140],\n",
              " 41: [500, 1140, 2500, 3140],\n",
              " 42: [1000, 1640, 2500, 3140],\n",
              " 43: [1500, 2140, 2500, 3140],\n",
              " 44: [2000, 2640, 2500, 3140],\n",
              " 45: [2500, 3140, 2500, 3140],\n",
              " 46: [3000, 3640, 2500, 3140],\n",
              " 47: [3500, 4140, 2500, 3140]}"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slicing_dict = {}\n",
        "\n",
        "for i in range (0, 48):\n",
        "    #print(f'value: {coordinates_list[i]}')\n",
        "    slice_1, slice_2 = coordinates_list[i][0], coordinates_list[i][1]\n",
        "    #print(slice_1, slice_2)\n",
        "    slice_1_a = slice_1\n",
        "    slice_1_b = slice_1_a + slize_size\n",
        "    slice_2_a = slice_2\n",
        "    slice_2_b = slice_2_a + slize_size\n",
        "    # print(f'[{slice_1_a}:{slice_1_b}, {slice_2_a}:{slice_2_b}]')\n",
        "    slicing_dict[i] = [slice_1_a, slice_1_b, slice_2_a, slice_2_b]\n",
        "\n",
        "slicing_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgeXLVdjVOFY",
        "outputId": "10b19fb0-452f-4ce5-a6bd-7ec12130ad62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slicing_dict[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "QQ2gg1NnU3wp"
      },
      "outputs": [],
      "source": [
        "list_of_tensors = [tensor_ones[slicing_dict[ele][0]:slicing_dict[ele][1], slicing_dict[ele][2]:slicing_dict[ele][3], ] for ele in range (0, 48)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kPHrXnNWQQ8",
        "outputId": "dce96ba1-fa68-4526-90ca-04da6035e8da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48, 640, 640, 3)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_list = np.array(list_of_tensors)\n",
        "tensor_list.shape # = (48, 640, 640, 3)\n",
        "# = 48 Tensors with width 640, height 640, 3 Colors (RGB)\n",
        "# YAAAAAAY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiqQ35PDx8-e"
      },
      "outputs": [],
      "source": [
        "slicing_dicti"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
