{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MUlsJO7-zYqv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "# import matplotlib.pyplot as plt\n",
        "# from twelo import *\n",
        "from twelo.data import pad_image, pad_all_images\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# padding_amount = 70\n",
        "# input_path = '/Users/myself/Pictures/twelo Bootcamp Project/Training_Data_twelo/obj_Train_data/DJI_20230504173742_0003_V.JPG'\n",
        "\n",
        "# tensor_ex = pad_image(input_path, padding_amount=70)\n",
        "# tensor_ex.shape\n",
        "\n",
        "# tensor_ex = tensor_ex.numpy()\n",
        "# tensor_ex.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "519"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting the names\n",
        "\n",
        "# Define the directory to search for .txt files\n",
        "directory_path = '/Users/myself/Pictures/twelo Bootcamp Project/Training_Data_twelo/obj_Train_data'\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "all_files = os.listdir(directory_path)\n",
        "\n",
        "# Filter the list to include only .txt files and sort them\n",
        "img_files = sorted([f for f in all_files if f.endswith('.JPG')])\n",
        "\n",
        "# Filter the list to include only .txt files and create a dictionary\n",
        "# txt_files_dict = {f: os.path.join(directory_path, f) for f in all_files if f.endswith('.txt')}\n",
        "# Create a dictionary with the sorted .txt files\n",
        "img_files_dict = {f: os.path.join(directory_path, f) for f in img_files}\n",
        "\n",
        "# Print the resulting dictionary\n",
        "# print(txt_files_dict)\n",
        "\n",
        "list_imgs = []\n",
        "list_img_names = []\n",
        "a = 0\n",
        "\n",
        "for key, value in img_files_dict.items():\n",
        "   # print(key, value)\n",
        "   if a < 525:\n",
        "       list_imgs.append(value)\n",
        "       list_img_names.append(key)\n",
        "   a += 1\n",
        "\n",
        "len(list_img_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['DJI_20230504181223_0001_V.JPG',\n",
              " 'DJI_20230504181223_0002_V.JPG',\n",
              " 'DJI_20230504181224_0003_V.JPG',\n",
              " 'DJI_20230504181225_0004_V.JPG',\n",
              " 'DJI_20230504181226_0005_V.JPG',\n",
              " 'DJI_20230504181226_0006_V.JPG',\n",
              " 'DJI_20230504181227_0007_V.JPG',\n",
              " 'DJI_20230504181228_0008_V.JPG',\n",
              " 'DJI_20230504181228_0009_V.JPG',\n",
              " 'DJI_20230504181229_0010_V.JPG',\n",
              " 'DJI_20230504181230_0011_V.JPG',\n",
              " 'DJI_20230504181231_0012_V.JPG',\n",
              " 'DJI_20230504181231_0013_V.JPG',\n",
              " 'DJI_20230504181232_0014_V.JPG',\n",
              " 'DJI_20230504181233_0015_V.JPG',\n",
              " 'DJI_20230504181233_0016_V.JPG',\n",
              " 'DJI_20230504181234_0017_V.JPG',\n",
              " 'DJI_20230504181235_0018_V.JPG',\n",
              " 'DJI_20230504181235_0019_V.JPG',\n",
              " 'DJI_20230504181236_0020_V.JPG',\n",
              " 'DJI_20230504181237_0021_V.JPG',\n",
              " 'DJI_20230504181238_0022_V.JPG',\n",
              " 'DJI_20230504181238_0023_V.JPG',\n",
              " 'DJI_20230504181239_0024_V.JPG',\n",
              " 'DJI_20230504181240_0025_V.JPG',\n",
              " 'DJI_20230504181240_0026_V.JPG',\n",
              " 'DJI_20230504181241_0027_V.JPG',\n",
              " 'DJI_20230504181242_0028_V.JPG',\n",
              " 'DJI_20230504181242_0029_V.JPG',\n",
              " 'DJI_20230504181243_0030_V.JPG',\n",
              " 'DJI_20230504181244_0031_V.JPG',\n",
              " 'DJI_20230504181245_0032_V.JPG',\n",
              " 'DJI_20230504181245_0033_V.JPG',\n",
              " 'DJI_20230504181246_0034_V.JPG',\n",
              " 'DJI_20230504181247_0035_V.JPG',\n",
              " 'DJI_20230504181247_0036_V.JPG',\n",
              " 'DJI_20230504181248_0037_V.JPG',\n",
              " 'DJI_20230504181249_0038_V.JPG',\n",
              " 'DJI_20230504181250_0039_V.JPG',\n",
              " 'DJI_20230504181250_0040_V.JPG',\n",
              " 'DJI_20230504181251_0041_V.JPG',\n",
              " 'DJI_20230504181252_0042_V.JPG',\n",
              " 'DJI_20230504181252_0043_V.JPG',\n",
              " 'DJI_20230504181253_0044_V.JPG',\n",
              " 'DJI_20230504181254_0045_V.JPG',\n",
              " 'DJI_20230504181254_0046_V.JPG',\n",
              " 'DJI_20230504181255_0047_V.JPG',\n",
              " 'DJI_20230504181256_0048_V.JPG',\n",
              " 'DJI_20230504181257_0049_V.JPG',\n",
              " 'DJI_20230504181257_0050_V.JPG',\n",
              " 'DJI_20230504181258_0051_V.JPG',\n",
              " 'DJI_20230504181259_0052_V.JPG',\n",
              " 'DJI_20230504181259_0053_V.JPG',\n",
              " 'DJI_20230504181300_0054_V.JPG',\n",
              " 'DJI_20230504181301_0055_V.JPG',\n",
              " 'DJI_20230504181302_0056_V.JPG',\n",
              " 'DJI_20230504181302_0057_V.JPG',\n",
              " 'DJI_20230504181303_0058_V.JPG',\n",
              " 'DJI_20230504181304_0059_V.JPG',\n",
              " 'DJI_20230504181304_0060_V.JPG',\n",
              " 'DJI_20230504181305_0061_V.JPG',\n",
              " 'DJI_20230504181306_0062_V.JPG',\n",
              " 'DJI_20230504181306_0063_V.JPG',\n",
              " 'DJI_20230504181307_0064_V.JPG',\n",
              " 'DJI_20230504181308_0065_V.JPG',\n",
              " 'DJI_20230504181309_0066_V.JPG',\n",
              " 'DJI_20230504181309_0067_V.JPG',\n",
              " 'DJI_20230504181310_0068_V.JPG',\n",
              " 'DJI_20230504181311_0069_V.JPG',\n",
              " 'DJI_20230504181311_0070_V.JPG',\n",
              " 'DJI_20230504181312_0071_V.JPG',\n",
              " 'DJI_20230504181313_0072_V.JPG',\n",
              " 'DJI_20230504181313_0073_V.JPG',\n",
              " 'DJI_20230504181314_0074_V.JPG',\n",
              " 'DJI_20230504181315_0075_V.JPG',\n",
              " 'DJI_20230504181316_0076_V.JPG',\n",
              " 'DJI_20230504181316_0077_V.JPG',\n",
              " 'DJI_20230504181317_0078_V.JPG',\n",
              " 'DJI_20230504181318_0079_V.JPG',\n",
              " 'DJI_20230504181318_0080_V.JPG',\n",
              " 'DJI_20230504181319_0081_V.JPG',\n",
              " 'DJI_20230504181320_0082_V.JPG',\n",
              " 'DJI_20230504181321_0083_V.JPG',\n",
              " 'DJI_20230504181321_0084_V.JPG',\n",
              " 'DJI_20230504181322_0085_V.JPG',\n",
              " 'DJI_20230504181323_0086_V.JPG',\n",
              " 'DJI_20230504181323_0087_V.JPG',\n",
              " 'DJI_20230504181324_0088_V.JPG',\n",
              " 'DJI_20230504181325_0089_V.JPG',\n",
              " 'DJI_20230504181325_0090_V.JPG',\n",
              " 'DJI_20230504181326_0091_V.JPG',\n",
              " 'DJI_20230504181327_0092_V.JPG',\n",
              " 'DJI_20230504181328_0093_V.JPG',\n",
              " 'DJI_20230504181328_0094_V.JPG',\n",
              " 'DJI_20230504181329_0095_V.JPG',\n",
              " 'DJI_20230504181330_0096_V.JPG',\n",
              " 'DJI_20230504181330_0097_V.JPG',\n",
              " 'DJI_20230504181331_0098_V.JPG',\n",
              " 'DJI_20230504181332_0099_V.JPG',\n",
              " 'DJI_20230504181332_0100_V.JPG',\n",
              " 'DJI_20230504182911_0001_V.JPG',\n",
              " 'DJI_20230504182911_0002_V.JPG',\n",
              " 'DJI_20230504182912_0003_V.JPG',\n",
              " 'DJI_20230504182913_0004_V.JPG',\n",
              " 'DJI_20230504182913_0005_V.JPG',\n",
              " 'DJI_20230504182914_0006_V.JPG',\n",
              " 'DJI_20230504182915_0007_V.JPG',\n",
              " 'DJI_20230504182916_0008_V.JPG',\n",
              " 'DJI_20230504182916_0009_V.JPG',\n",
              " 'DJI_20230504182917_0010_V.JPG',\n",
              " 'DJI_20230504182918_0011_V.JPG',\n",
              " 'DJI_20230504182918_0012_V.JPG',\n",
              " 'DJI_20230504182919_0013_V.JPG',\n",
              " 'DJI_20230504182920_0014_V.JPG',\n",
              " 'DJI_20230504182920_0015_V.JPG',\n",
              " 'DJI_20230504182921_0016_V.JPG',\n",
              " 'DJI_20230504182922_0017_V.JPG',\n",
              " 'DJI_20230504182923_0018_V.JPG',\n",
              " 'DJI_20230504182923_0019_V.JPG',\n",
              " 'DJI_20230504182924_0020_V.JPG',\n",
              " 'DJI_20230504182925_0021_V.JPG',\n",
              " 'DJI_20230504182925_0022_V.JPG',\n",
              " 'DJI_20230504182926_0023_V.JPG',\n",
              " 'DJI_20230504182927_0024_V.JPG',\n",
              " 'DJI_20230504182928_0025_V.JPG',\n",
              " 'DJI_20230504182928_0026_V.JPG',\n",
              " 'DJI_20230504182929_0027_V.JPG',\n",
              " 'DJI_20230504182930_0028_V.JPG',\n",
              " 'DJI_20230504182930_0029_V.JPG',\n",
              " 'DJI_20230504182931_0030_V.JPG',\n",
              " 'DJI_20230504182932_0031_V.JPG',\n",
              " 'DJI_20230504182932_0032_V.JPG',\n",
              " 'DJI_20230504182933_0033_V.JPG',\n",
              " 'DJI_20230504182934_0034_V.JPG',\n",
              " 'DJI_20230504182935_0035_V.JPG',\n",
              " 'DJI_20230504182935_0036_V.JPG',\n",
              " 'DJI_20230504182936_0037_V.JPG',\n",
              " 'DJI_20230504182937_0038_V.JPG',\n",
              " 'DJI_20230504182937_0039_V.JPG',\n",
              " 'DJI_20230504182938_0040_V.JPG',\n",
              " 'DJI_20230504182939_0041_V.JPG',\n",
              " 'DJI_20230504182939_0042_V.JPG',\n",
              " 'DJI_20230504182940_0043_V.JPG',\n",
              " 'DJI_20230504182941_0044_V.JPG',\n",
              " 'DJI_20230504182942_0045_V.JPG',\n",
              " 'DJI_20230504182942_0046_V.JPG',\n",
              " 'DJI_20230504182943_0047_V.JPG',\n",
              " 'DJI_20230504182944_0048_V.JPG',\n",
              " 'DJI_20230504182944_0049_V.JPG',\n",
              " 'DJI_20230504182945_0050_V.JPG',\n",
              " 'DJI_20230504182946_0051_V.JPG',\n",
              " 'DJI_20230504182947_0052_V.JPG',\n",
              " 'DJI_20230504182947_0053_V.JPG',\n",
              " 'DJI_20230504182948_0054_V.JPG',\n",
              " 'DJI_20230504182949_0055_V.JPG',\n",
              " 'DJI_20230504182949_0056_V.JPG',\n",
              " 'DJI_20230504182950_0057_V.JPG',\n",
              " 'DJI_20230504182951_0058_V.JPG',\n",
              " 'DJI_20230504182951_0059_V.JPG',\n",
              " 'DJI_20230504182952_0060_V.JPG',\n",
              " 'DJI_20230504182953_0061_V.JPG',\n",
              " 'DJI_20230504182954_0062_V.JPG',\n",
              " 'DJI_20230504182954_0063_V.JPG',\n",
              " 'DJI_20230504182955_0064_V.JPG',\n",
              " 'DJI_20230504182956_0065_V.JPG',\n",
              " 'DJI_20230504182956_0066_V.JPG',\n",
              " 'DJI_20230504182957_0067_V.JPG',\n",
              " 'DJI_20230504182958_0068_V.JPG',\n",
              " 'DJI_20230504182958_0069_V.JPG',\n",
              " 'DJI_20230504182959_0070_V.JPG',\n",
              " 'DJI_20230504183000_0071_V.JPG',\n",
              " 'DJI_20230504183001_0072_V.JPG',\n",
              " 'DJI_20230504183001_0073_V.JPG',\n",
              " 'DJI_20230504183002_0074_V.JPG',\n",
              " 'DJI_20230504183003_0075_V.JPG',\n",
              " 'DJI_20230504183003_0076_V.JPG',\n",
              " 'DJI_20230504183004_0077_V.JPG',\n",
              " 'DJI_20230504183005_0078_V.JPG',\n",
              " 'DJI_20230504183006_0079_V.JPG',\n",
              " 'DJI_20230504183006_0080_V.JPG',\n",
              " 'DJI_20230504183007_0081_V.JPG',\n",
              " 'DJI_20230504183008_0082_V.JPG',\n",
              " 'DJI_20230504183008_0083_V.JPG',\n",
              " 'DJI_20230504183009_0084_V.JPG',\n",
              " 'DJI_20230504183010_0085_V.JPG',\n",
              " 'DJI_20230504183010_0086_V.JPG',\n",
              " 'DJI_20230504183011_0087_V.JPG',\n",
              " 'DJI_20230504183012_0088_V.JPG',\n",
              " 'DJI_20230504183013_0089_V.JPG',\n",
              " 'DJI_20230504183013_0090_V.JPG',\n",
              " 'DJI_20230504183014_0091_V.JPG',\n",
              " 'DJI_20230504183015_0092_V.JPG',\n",
              " 'DJI_20230504183015_0093_V.JPG',\n",
              " 'DJI_20230504183016_0094_V.JPG',\n",
              " 'DJI_20230504183017_0095_V.JPG',\n",
              " 'DJI_20230504183017_0096_V.JPG',\n",
              " 'DJI_20230504183018_0097_V.JPG',\n",
              " 'DJI_20230504183019_0098_V.JPG',\n",
              " 'DJI_20230504183020_0099_V.JPG',\n",
              " 'DJI_20230504183020_0100_V.JPG',\n",
              " 'DJI_20230504183021_0101_V.JPG',\n",
              " 'DJI_20230504183022_0102_V.JPG',\n",
              " 'DJI_20230504183022_0103_V.JPG',\n",
              " 'DJI_20230504183023_0104_V.JPG',\n",
              " 'DJI_20230504183024_0105_V.JPG',\n",
              " 'DJI_20230504183025_0106_V.JPG',\n",
              " 'DJI_20230504183025_0107_V.JPG',\n",
              " 'DJI_20230504183026_0108_V.JPG',\n",
              " 'DJI_20230504183027_0109_V.JPG',\n",
              " 'DJI_20230504183027_0110_V.JPG',\n",
              " 'DJI_20230504183028_0111_V.JPG',\n",
              " 'DJI_20230504183029_0112_V.JPG',\n",
              " 'DJI_20230504183029_0113_V.JPG',\n",
              " 'DJI_20230504183030_0114_V.JPG',\n",
              " 'DJI_20230504183031_0115_V.JPG',\n",
              " 'DJI_20230504183032_0116_V.JPG',\n",
              " 'DJI_20230504183032_0117_V.JPG',\n",
              " 'DJI_20230504183033_0118_V.JPG',\n",
              " 'DJI_20230504183034_0119_V.JPG',\n",
              " 'DJI_20230504183034_0120_V.JPG',\n",
              " 'DJI_20230504183035_0121_V.JPG',\n",
              " 'DJI_20230504183036_0122_V.JPG',\n",
              " 'DJI_20230504183036_0123_V.JPG',\n",
              " 'DJI_20230504183037_0124_V.JPG',\n",
              " 'DJI_20230504183038_0125_V.JPG',\n",
              " 'DJI_20230504183039_0126_V.JPG',\n",
              " 'DJI_20230504183039_0127_V.JPG',\n",
              " 'DJI_20230504183040_0128_V.JPG',\n",
              " 'DJI_20230504183041_0129_V.JPG',\n",
              " 'DJI_20230504183041_0130_V.JPG',\n",
              " 'DJI_20230504183042_0131_V.JPG',\n",
              " 'DJI_20230504183043_0132_V.JPG',\n",
              " 'DJI_20230504183043_0133_V.JPG',\n",
              " 'DJI_20230504183044_0134_V.JPG',\n",
              " 'DJI_20230504183045_0135_V.JPG',\n",
              " 'DJI_20230504183046_0136_V.JPG',\n",
              " 'DJI_20230504183046_0137_V.JPG',\n",
              " 'DJI_20230504183047_0138_V.JPG',\n",
              " 'DJI_20230504183048_0139_V.JPG',\n",
              " 'DJI_20230504183048_0140_V.JPG',\n",
              " 'DJI_20230504183049_0141_V.JPG',\n",
              " 'DJI_20230504183050_0142_V.JPG',\n",
              " 'DJI_20230504183051_0143_V.JPG',\n",
              " 'DJI_20230504183051_0144_V.JPG',\n",
              " 'DJI_20230504183052_0145_V.JPG',\n",
              " 'DJI_20230504183053_0146_V.JPG',\n",
              " 'DJI_20230504183053_0147_V.JPG',\n",
              " 'DJI_20230504183054_0148_V.JPG',\n",
              " 'DJI_20230504183055_0149_V.JPG',\n",
              " 'DJI_20230504183055_0150_V.JPG']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_img_names = list_img_names[269:]\n",
        "list_img_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(list_img_names)\n",
        "list_img_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "names_164 = list(list_img_names[105:269])\n",
        "len(names_164)\n",
        "names_164\n",
        "\n",
        "names_250 = list(list_img_names[269:])\n",
        "len(names_250)\n",
        "names_250\n",
        "\n",
        "names_105 = list(list_img_names[0:105])\n",
        "names_105"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding all images.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 105/105 [00:14<00:00,  7.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished padding all images. Output shape: [105, 3140, 4140, 3]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([105, 3140, 4140, 3])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting FIRST 105 the training_data\n",
        "# DONT RUN THIS AGAIN!!!\n",
        "\n",
        "padding_amount = 70\n",
        "input_path_folder = '/Users/myself/Pictures/twelo Bootcamp Project/Training_Data_twelo/first_105'\n",
        "\n",
        "tensor_of_all_tensors = pad_all_images(input_path_folder)\n",
        "tensor_of_all_tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding all images.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 164/164 [00:21<00:00,  7.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished padding all images. Output shape: [164, 3140, 4140, 3]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([164, 3140, 4140, 3])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting SECOND 164 the training_data\n",
        "# DONT RUN THIS AGAIN!!!\n",
        "\n",
        "padding_amount = 70\n",
        "input_path_folder = '/Users/myself/Pictures/twelo Bootcamp Project/Training_Data_twelo/second_164'\n",
        "\n",
        "tensor_of_all_tensors = pad_all_images(input_path_folder)\n",
        "tensor_of_all_tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding all images.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [00:35<00:00,  7.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished padding all images. Output shape: [250, 3140, 4140, 3]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([250, 3140, 4140, 3])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting THIRD 250 the training_data\n",
        "# DONT RUN THIS AGAIN!!!\n",
        "\n",
        "padding_amount = 70\n",
        "input_path_folder = '/Users/myself/Pictures/twelo Bootcamp Project/Training_Data_twelo/third_250'\n",
        "\n",
        "tensor_of_all_tensors = pad_all_images(input_path_folder)\n",
        "tensor_of_all_tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(164, 3140, 4140, 3)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_of_all_tensors = tensor_of_all_tensors.numpy()\n",
        "tensor_of_all_tensors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QXgwNl2c-BO"
      },
      "source": [
        "# Function: **luc_coordinates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wVVGT1tdXaeO"
      },
      "outputs": [],
      "source": [
        "def luc_coordinates(width, height, num_width_comp, num_height_comp, comp_size):\n",
        "  ''' A function that takes as an input:\n",
        "  width_comp = number of compartments for the width (e.g. 8)\n",
        "  height_comp = number of compartments for the height (e.g. 6)\n",
        "  comp_size = size of each compartment (e.g. 640)\n",
        "  and returns the coordinates of the left-upper-corner (luc) of\n",
        "  each compartment\n",
        "  '''\n",
        "\n",
        "  # Step size is the size of the compartments unique pixels horizontally and vertically\n",
        "  step_size_horiz = width / num_width_comp\n",
        "  step_size_vert = height / num_height_comp\n",
        "\n",
        "  # Defining how much overlap there will be between each compartment vertically and horizontally\n",
        "  overlap_horiz = int(((comp_size * num_width_comp) - width)/num_width_comp)\n",
        "  overlap_vert = int(((comp_size * num_height_comp) - height)/num_height_comp)\n",
        "\n",
        "  #creating a list with all the x_coordinates for the compartments (8)\n",
        "  x_coordinates = [0]\n",
        "  [x_coordinates.append(int(ele * step_size_horiz)) for ele in range(1, num_width_comp)]\n",
        "\n",
        "  # creating a list with all the y_coordinates for the compartments (6)\n",
        "  y_coordinates = [0]\n",
        "  [y_coordinates.append(int(ele * step_size_vert)) for ele in range(1, num_height_comp)]\n",
        "\n",
        "\n",
        "  # Creating a dictionary with the coordinates\n",
        "  coordinates_dict = {}\n",
        "  b = 0 # no inherent important meaning\n",
        "\n",
        "  for ele in range (0, num_height_comp):\n",
        "    for i in range (0, num_width_comp):\n",
        "      a = [x_coordinates[i], y_coordinates[ele]]\n",
        "      b += 1\n",
        "      coordinates_dict[f'cor_{b}'] = a\n",
        "\n",
        "  return coordinates_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Defining the inputs of the function\n",
        "\n",
        "width = 4000\n",
        "height = 3000\n",
        "\n",
        "num_width_comp = 8\n",
        "num_height_comp = 6\n",
        "comp_size = 640\n",
        "\n",
        "# coordinates_dict = luc_coordinates(width, height, num_width_comp, num_height_comp, comp_size)\n",
        "# coordinates_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwKh9pskc1E7"
      },
      "source": [
        "# Function: **splitting_into_compartments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RrcFVt4KX3xo"
      },
      "outputs": [],
      "source": [
        "def splitting_into_compartments(tensor):\n",
        "  '''\n",
        "  Takes as an input the Tensor that represents the\n",
        "  whole image that is supposed to be split into compartments.\n",
        "  The tensor should have the shape (4140, 3140, 3)\n",
        "  '''\n",
        "\n",
        "  # Calling the function 'luc_coordinates' and saving the resulting dictionary of coordinates in a variable\n",
        "  coordinates_dict = luc_coordinates(width, height, num_width_comp, num_height_comp, comp_size)\n",
        "\n",
        "  slize_size = 640\n",
        "\n",
        "  # Turning the coordinates into a list\n",
        "  coordinates_list = [value for key, value in coordinates_dict.items()]\n",
        "\n",
        "  # creating a for loop for getting the correct slizing integers and putting them into a dictionary\n",
        "  slicing_dict = {}\n",
        "\n",
        "  for i in range (0, 48):\n",
        "    slice_1, slice_2 = coordinates_list[i][0], coordinates_list[i][1]\n",
        "    slice_1_a = slice_1\n",
        "    slice_1_b = slice_1_a + slize_size\n",
        "    slice_2_a = slice_2\n",
        "    slice_2_b = slice_2_a + slize_size\n",
        "    slicing_dict[i] = [slice_1_a, slice_1_b, slice_2_a, slice_2_b]\n",
        "\n",
        "  # slicing the input-tensor to get (48) of shape (640, 640, 3)\n",
        "\n",
        "  # version tensor.shape = (4140, 3140, 3)\n",
        "#   list_of_tensors = [tensor[slicing_dict[ele][0]:slicing_dict[ele][1],\n",
        "#                                  slicing_dict[ele][2]:slicing_dict[ele][3],\n",
        "\n",
        "#                                  ] for ele in range (0, 48)]\n",
        "\n",
        "  #version tensor.shape = (3140, 4140, 3)\n",
        "  list_of_tensors = [tensor[slicing_dict[ele][2]:slicing_dict[ele][3],\n",
        "                            slicing_dict[ele][0]:slicing_dict[ele][1],\n",
        "\n",
        "                                 ] for ele in range (0, 48)]\n",
        "\n",
        "  #optional, if needed:\n",
        "  compartment_tensors = np.array(list_of_tensors)\n",
        "\n",
        "  return compartment_tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105, 3140, 4140, 3)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_of_all_tensors.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48,)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tensor = tensor_of_all_tensors\n",
        "# compartment_tensors = splitting_into_compartments(tensor)\n",
        "# compartment_tensors.shape\n",
        "\n",
        "# # a = compartment_tensors[0,:,:,:]\n",
        "# # b = compartment_tensors[1,:,:,:]\n",
        "# # c = compartment_tensors[2,:,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105, 3140, 4140, 3)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "\n",
        "# # Assuming your tensor is a NumPy array\n",
        "# tensor = np.random.randint(0, 256, (640, 640, 3), dtype=np.uint8)\n",
        "# tensor.shape\n",
        "\n",
        "# # Convert the NumPy array to an Image object\n",
        "# image = Image.fromarray(a)\n",
        "\n",
        "# # Save the image as a PNG file\n",
        "# image.save('output_image.png')\n",
        "\n",
        "# # Or save as a JPEG file\n",
        "# image.save('output_image.jpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(164, 3140, 4140, 3)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_of_all_tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Can be put into a function as well\n",
        "\n",
        "for k in range(0, tensor_of_all_tensors.shape[0]):\n",
        "    tensor = tensor_of_all_tensors[k,:,:,:]\n",
        "    # print(tensor.shape)\n",
        "    compartment_tensors = splitting_into_compartments(tensor)\n",
        "    # print(compartment_tensors.shape)\n",
        "    for i in range(0, 48):\n",
        "        compartment = compartment_tensors[i,:,:,:]  # object shape (640, 640, 3)\n",
        "        image = Image.fromarray(compartment)\n",
        "        image.save(f'/Users/myself/twelo_Project/data/annother_try_images/{list_img_names[k]}_{i}.jpg')\n",
        "\n",
        "    # Should do the trick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZSC6zRqDZWu8",
        "outputId": "9d93c88d-f4de-4da3-c87f-b7ed0eaaa3c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 91.8 ms, sys: 220 ms, total: 311 ms\n",
            "Wall time: 313 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(48, 640, 640, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "tensor_ones = np.ones((4140, 3140, 3))\n",
        "splitting_into_compartments(tensor_ones).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "from twelo.data import *\n",
        "from twelo.visualization import visualize_bounding_box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected `boxes` to be a Tensor with a final dimension of `4`. Instead, got `boxes.shape=(4, 0)`.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/myself/Kestrix_Project/data/tensor_ex/New Folder With Items\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvisualize_bounding_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Kestrix_Project/kestrix/visualization.py:23\u001b[0m, in \u001b[0;36mvisualize_bounding_box\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     20\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batched_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     22\u001b[0m images, bounding_boxes \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m], inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_boxes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m \u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_bounding_box_gallery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounding_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfont_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounding_box_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBOUNDING_BOX_FORMAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCLASS_MAPPING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/kestrix/lib/python3.10/site-packages/keras_cv/src/visualization/plot_bounding_box_gallery.py:139\u001b[0m, in \u001b[0;36mplot_bounding_box_gallery\u001b[0;34m(images, value_range, bounding_box_format, y_true, y_pred, true_color, pred_color, line_thickness, font_scale, text_thickness, class_mapping, ground_truth_mapping, prediction_mapping, legend, legend_handles, rows, cols, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     y_true[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_numpy(y_true[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    138\u001b[0m     y_true[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_numpy(y_true[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 139\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m \u001b[43mbounding_box\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounding_box_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxyxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     plotted_images \u001b[38;5;241m=\u001b[39m draw_fn(\n\u001b[1;32m    143\u001b[0m         plotted_images,\n\u001b[1;32m    144\u001b[0m         y_true,\n\u001b[1;32m    145\u001b[0m         true_color,\n\u001b[1;32m    146\u001b[0m         class_mapping\u001b[38;5;241m=\u001b[39mground_truth_mapping,\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_pred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/kestrix/lib/python3.10/site-packages/keras_cv/src/backend/scope.py:37\u001b[0m, in \u001b[0;36mtf_data.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/kestrix/lib/python3.10/site-packages/keras_cv/src/bounding_box/converters.py:374\u001b[0m, in \u001b[0;36mconvert_format\u001b[0;34m(boxes, source, target, images, image_shape, dtype)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(boxes, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    373\u001b[0m     converted_boxes \u001b[38;5;241m=\u001b[39m boxes\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 374\u001b[0m     converted_boxes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_boxes\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m boxes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m boxes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/kestrix/lib/python3.10/site-packages/keras_cv/src/backend/scope.py:37\u001b[0m, in \u001b[0;36mtf_data.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/kestrix/lib/python3.10/site-packages/keras_cv/src/bounding_box/converters.py:385\u001b[0m, in \u001b[0;36mconvert_format\u001b[0;34m(boxes, source, target, images, image_shape, dtype)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_boxes\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m boxes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m boxes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `boxes` to be a Tensor with a final dimension of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`4`. Instead, got `boxes.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mboxes\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m     )\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m image_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_format() expects either `images` or `image_shape`, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot both. Received images=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m image_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected `boxes` to be a Tensor with a final dimension of `4`. Instead, got `boxes.shape=(4, 0)`."
          ]
        }
      ],
      "source": [
        "path = '/Users/myself/twelo_Project/data/tensor_ex/New Folder With Items'\n",
        "\n",
        "visualize_bounding_box(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtY97t5sdF2-"
      },
      "source": [
        "# Function: **slicing_dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qyL8Fw-adN0A"
      },
      "outputs": [],
      "source": [
        "def slicing_dictionary(tensor):\n",
        "\n",
        "  # Calling the function 'luc_coordinates' and saving the resulting dictionary of coordinates in a variable\n",
        "  coordinates_dict = luc_coordinates(num_width_comp, num_height_comp, comp_size)\n",
        "\n",
        "  slize_size = 640\n",
        "\n",
        "  # Turning the coordinates into a list\n",
        "  coordinates_list = [value for key, value in coordinates_dict.items()]\n",
        "\n",
        "  # creating a for loop for getting the correct slizing integers and putting them into a dictionary\n",
        "  slicing_dict = {}\n",
        "\n",
        "  for i in range (0, 48):\n",
        "    slice_1, slice_2 = coordinates_list[i][0], coordinates_list[i][1]\n",
        "    slice_1_a = slice_1\n",
        "    slice_1_b = slice_1_a + slize_size\n",
        "    slice_2_a = slice_2\n",
        "    slice_2_b = slice_2_a + slize_size\n",
        "    slicing_dict[i] = [slice_1_a, slice_1_b, slice_2_a, slice_2_b]\n",
        "\n",
        "  return slicing_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwhMoxMtdiwr",
        "outputId": "6fee1d6d-290f-4335-bd6c-d43e92436f03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [0, 640, 0, 640],\n",
              " 1: [500, 1140, 0, 640],\n",
              " 2: [1000, 1640, 0, 640],\n",
              " 3: [1500, 2140, 0, 640],\n",
              " 4: [2000, 2640, 0, 640],\n",
              " 5: [2500, 3140, 0, 640],\n",
              " 6: [3000, 3640, 0, 640],\n",
              " 7: [3500, 4140, 0, 640],\n",
              " 8: [0, 640, 500, 1140],\n",
              " 9: [500, 1140, 500, 1140],\n",
              " 10: [1000, 1640, 500, 1140],\n",
              " 11: [1500, 2140, 500, 1140],\n",
              " 12: [2000, 2640, 500, 1140],\n",
              " 13: [2500, 3140, 500, 1140],\n",
              " 14: [3000, 3640, 500, 1140],\n",
              " 15: [3500, 4140, 500, 1140],\n",
              " 16: [0, 640, 1000, 1640],\n",
              " 17: [500, 1140, 1000, 1640],\n",
              " 18: [1000, 1640, 1000, 1640],\n",
              " 19: [1500, 2140, 1000, 1640],\n",
              " 20: [2000, 2640, 1000, 1640],\n",
              " 21: [2500, 3140, 1000, 1640],\n",
              " 22: [3000, 3640, 1000, 1640],\n",
              " 23: [3500, 4140, 1000, 1640],\n",
              " 24: [0, 640, 1500, 2140],\n",
              " 25: [500, 1140, 1500, 2140],\n",
              " 26: [1000, 1640, 1500, 2140],\n",
              " 27: [1500, 2140, 1500, 2140],\n",
              " 28: [2000, 2640, 1500, 2140],\n",
              " 29: [2500, 3140, 1500, 2140],\n",
              " 30: [3000, 3640, 1500, 2140],\n",
              " 31: [3500, 4140, 1500, 2140],\n",
              " 32: [0, 640, 2000, 2640],\n",
              " 33: [500, 1140, 2000, 2640],\n",
              " 34: [1000, 1640, 2000, 2640],\n",
              " 35: [1500, 2140, 2000, 2640],\n",
              " 36: [2000, 2640, 2000, 2640],\n",
              " 37: [2500, 3140, 2000, 2640],\n",
              " 38: [3000, 3640, 2000, 2640],\n",
              " 39: [3500, 4140, 2000, 2640],\n",
              " 40: [0, 640, 2500, 3140],\n",
              " 41: [500, 1140, 2500, 3140],\n",
              " 42: [1000, 1640, 2500, 3140],\n",
              " 43: [1500, 2140, 2500, 3140],\n",
              " 44: [2000, 2640, 2500, 3140],\n",
              " 45: [2500, 3140, 2500, 3140],\n",
              " 46: [3000, 3640, 2500, 3140],\n",
              " 47: [3500, 4140, 2500, 3140]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_ones = np.ones((4140, 3140, 3))\n",
        "slicing_dictionary(tensor_ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBIRVA98xkF8"
      },
      "source": [
        "# Step after Step for the 'luc_coordinates'-function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6SmXaT7kxTEP"
      },
      "outputs": [],
      "source": [
        "# 1. compartment\n",
        "width = 4000\n",
        "height = 3000\n",
        "\n",
        "#Defining the inputs of the function\n",
        "num_width_comp = 8\n",
        "num_height_comp = 6\n",
        "comp_size = 640\n",
        "\n",
        " # Step size is the size of the compartments unique pixels horizontally and vertically\n",
        "step_size_horiz = width / num_width_comp # = 500\n",
        "step_size_vert = height / num_height_comp # = 500\n",
        "\n",
        "# Defining how much overlap there will be between each compartment vertically and horizontally\n",
        "overlap_horiz = int(((comp_size * num_width_comp) - width)/num_width_comp) # = 140\n",
        "overlap_vert = int(((comp_size * num_height_comp) - height)/num_height_comp) # = 140"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACeSSxbtdfPx",
        "outputId": "030f6388-f8e6-4085-f5ca-2c0518547687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
            "[0, 500, 1000, 1500, 2000, 2500]\n"
          ]
        }
      ],
      "source": [
        "#creating a list with all the x_coordinates for the first row of compartments (8)\n",
        "x_coordinates = [0]\n",
        "[x_coordinates.append(int(ele * step_size_horiz)) for ele in range(1, num_width_comp)]\n",
        "\n",
        "# Coordinates we want for a shape of (4140, 3140): [0, 500, 1000, 1500, 2000, 2500, 3000, 3500]\n",
        "\n",
        "# creating a list with all the y_coordinates for the first row of compartments (8)\n",
        "# Is always the same coordinate -> 0 (or 1)\n",
        "y_coordinates = [0]\n",
        "[y_coordinates.append(int(ele * step_size_vert)) for ele in range(1, num_height_comp)]\n",
        "\n",
        "print(x_coordinates)\n",
        "print(y_coordinates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VvdKDd_cVCS"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: For achieving the same overlap for each compartment, we need to add padding of 70 pixels at each side of the total image (4000 x 3000)\n",
        "# -> The tensor has to be increased at the right positions by that\n",
        "# IMPORTANT: The coordinates have to altered when adding the padding (+ 70 each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxQPfJkrZaSo",
        "outputId": "7518576b-618a-457f-9a89-4f19cb891bb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cor_1': [0, 0],\n",
              " 'cor_2': [500, 0],\n",
              " 'cor_3': [1000, 0],\n",
              " 'cor_4': [1500, 0],\n",
              " 'cor_5': [2000, 0],\n",
              " 'cor_6': [2500, 0],\n",
              " 'cor_7': [3000, 0],\n",
              " 'cor_8': [3500, 0],\n",
              " 'cor_9': [0, 500],\n",
              " 'cor_10': [500, 500],\n",
              " 'cor_11': [1000, 500],\n",
              " 'cor_12': [1500, 500],\n",
              " 'cor_13': [2000, 500],\n",
              " 'cor_14': [2500, 500],\n",
              " 'cor_15': [3000, 500],\n",
              " 'cor_16': [3500, 500],\n",
              " 'cor_17': [0, 1000],\n",
              " 'cor_18': [500, 1000],\n",
              " 'cor_19': [1000, 1000],\n",
              " 'cor_20': [1500, 1000],\n",
              " 'cor_21': [2000, 1000],\n",
              " 'cor_22': [2500, 1000],\n",
              " 'cor_23': [3000, 1000],\n",
              " 'cor_24': [3500, 1000],\n",
              " 'cor_25': [0, 1500],\n",
              " 'cor_26': [500, 1500],\n",
              " 'cor_27': [1000, 1500],\n",
              " 'cor_28': [1500, 1500],\n",
              " 'cor_29': [2000, 1500],\n",
              " 'cor_30': [2500, 1500],\n",
              " 'cor_31': [3000, 1500],\n",
              " 'cor_32': [3500, 1500],\n",
              " 'cor_33': [0, 2000],\n",
              " 'cor_34': [500, 2000],\n",
              " 'cor_35': [1000, 2000],\n",
              " 'cor_36': [1500, 2000],\n",
              " 'cor_37': [2000, 2000],\n",
              " 'cor_38': [2500, 2000],\n",
              " 'cor_39': [3000, 2000],\n",
              " 'cor_40': [3500, 2000],\n",
              " 'cor_41': [0, 2500],\n",
              " 'cor_42': [500, 2500],\n",
              " 'cor_43': [1000, 2500],\n",
              " 'cor_44': [1500, 2500],\n",
              " 'cor_45': [2000, 2500],\n",
              " 'cor_46': [2500, 2500],\n",
              " 'cor_47': [3000, 2500],\n",
              " 'cor_48': [3500, 2500]}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating each coordinate for the 48 compartments\n",
        "\n",
        "coordinates_dict = {}\n",
        "b = 0 # no inherent important meaning\n",
        "\n",
        "for ele in range (0, num_height_comp):\n",
        "  for i in range (0, num_width_comp):\n",
        "    a = [x_coordinates[i], y_coordinates[ele]]\n",
        "    b += 1\n",
        "    coordinates_dict[f'cor_{b}'] = a\n",
        "\n",
        "coordinates_dict\n",
        "\n",
        "# coordinates_dict -> contains values that represent x-coordinates and y_coordinates for the upper left corner of a compartment of the input size (e.g. 640 x 640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGGFbl9RcvMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izj5PApucFj8"
      },
      "source": [
        "# Step after Step for the 'splitting_into_compartments'-function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AL_3aszyZbI"
      },
      "outputs": [],
      "source": [
        "# Calling the function and saving the resulting dictionary of coordinates in a variable\n",
        "coordinates_dict = luc_coordinates(num_width_comp, num_height_comp, comp_size)\n",
        "\n",
        "# I want to have an output that slices the tensor nicely and comparts it into 48 tensors\n",
        "# Create a tensor filled with ones\n",
        "tensor_ones = np.ones((4140, 3140, 3))\n",
        "tensor_ones.shape\n",
        "\n",
        "tensor_ones[1:641, 1:641,].shape\n",
        "slize_size = 640\n",
        "\n",
        "coordinates_list = []\n",
        "\n",
        "\n",
        "for keys, value in coordinates_dict.items():\n",
        "  coordinates_list.append(value)\n",
        "\n",
        "coordinates_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSgVtHxbTmw4",
        "outputId": "b2c8bd8d-07b1-4697-99ff-a8b0f5e8d74b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [0, 640, 0, 640],\n",
              " 1: [500, 1140, 0, 640],\n",
              " 2: [1000, 1640, 0, 640],\n",
              " 3: [1500, 2140, 0, 640],\n",
              " 4: [2000, 2640, 0, 640],\n",
              " 5: [2500, 3140, 0, 640],\n",
              " 6: [3000, 3640, 0, 640],\n",
              " 7: [3500, 4140, 0, 640],\n",
              " 8: [0, 640, 500, 1140],\n",
              " 9: [500, 1140, 500, 1140],\n",
              " 10: [1000, 1640, 500, 1140],\n",
              " 11: [1500, 2140, 500, 1140],\n",
              " 12: [2000, 2640, 500, 1140],\n",
              " 13: [2500, 3140, 500, 1140],\n",
              " 14: [3000, 3640, 500, 1140],\n",
              " 15: [3500, 4140, 500, 1140],\n",
              " 16: [0, 640, 1000, 1640],\n",
              " 17: [500, 1140, 1000, 1640],\n",
              " 18: [1000, 1640, 1000, 1640],\n",
              " 19: [1500, 2140, 1000, 1640],\n",
              " 20: [2000, 2640, 1000, 1640],\n",
              " 21: [2500, 3140, 1000, 1640],\n",
              " 22: [3000, 3640, 1000, 1640],\n",
              " 23: [3500, 4140, 1000, 1640],\n",
              " 24: [0, 640, 1500, 2140],\n",
              " 25: [500, 1140, 1500, 2140],\n",
              " 26: [1000, 1640, 1500, 2140],\n",
              " 27: [1500, 2140, 1500, 2140],\n",
              " 28: [2000, 2640, 1500, 2140],\n",
              " 29: [2500, 3140, 1500, 2140],\n",
              " 30: [3000, 3640, 1500, 2140],\n",
              " 31: [3500, 4140, 1500, 2140],\n",
              " 32: [0, 640, 2000, 2640],\n",
              " 33: [500, 1140, 2000, 2640],\n",
              " 34: [1000, 1640, 2000, 2640],\n",
              " 35: [1500, 2140, 2000, 2640],\n",
              " 36: [2000, 2640, 2000, 2640],\n",
              " 37: [2500, 3140, 2000, 2640],\n",
              " 38: [3000, 3640, 2000, 2640],\n",
              " 39: [3500, 4140, 2000, 2640],\n",
              " 40: [0, 640, 2500, 3140],\n",
              " 41: [500, 1140, 2500, 3140],\n",
              " 42: [1000, 1640, 2500, 3140],\n",
              " 43: [1500, 2140, 2500, 3140],\n",
              " 44: [2000, 2640, 2500, 3140],\n",
              " 45: [2500, 3140, 2500, 3140],\n",
              " 46: [3000, 3640, 2500, 3140],\n",
              " 47: [3500, 4140, 2500, 3140]}"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slicing_dict = {}\n",
        "\n",
        "for i in range (0, 48):\n",
        "    #print(f'value: {coordinates_list[i]}')\n",
        "    slice_1, slice_2 = coordinates_list[i][0], coordinates_list[i][1]\n",
        "    #print(slice_1, slice_2)\n",
        "    slice_1_a = slice_1\n",
        "    slice_1_b = slice_1_a + slize_size\n",
        "    slice_2_a = slice_2\n",
        "    slice_2_b = slice_2_a + slize_size\n",
        "    # print(f'[{slice_1_a}:{slice_1_b}, {slice_2_a}:{slice_2_b}]')\n",
        "    slicing_dict[i] = [slice_1_a, slice_1_b, slice_2_a, slice_2_b]\n",
        "\n",
        "slicing_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgeXLVdjVOFY",
        "outputId": "10b19fb0-452f-4ce5-a6bd-7ec12130ad62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slicing_dict[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "QQ2gg1NnU3wp"
      },
      "outputs": [],
      "source": [
        "list_of_tensors = [tensor_ones[slicing_dict[ele][0]:slicing_dict[ele][1], slicing_dict[ele][2]:slicing_dict[ele][3], ] for ele in range (0, 48)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kPHrXnNWQQ8",
        "outputId": "dce96ba1-fa68-4526-90ca-04da6035e8da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48, 640, 640, 3)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_list = np.array(list_of_tensors)\n",
        "tensor_list.shape # = (48, 640, 640, 3)\n",
        "# = 48 Tensors with width 640, height 640, 3 Colors (RGB)\n",
        "# YAAAAAAY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiqQ35PDx8-e"
      },
      "outputs": [],
      "source": [
        "slicing_dicti"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
